{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e21946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2853\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 223454.500000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2853\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1100000.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "\n",
      "==== LightGBM VALIDATION ====\n",
      "coverage: 0.77325\n",
      "width: 206914.04286457325\n",
      "mae_mid: 70108.02038310506\n",
      "pinball10: 14883.050492967912\n",
      "pinball90: 17401.855880261606\n",
      "\n",
      "==== XGBoost VALIDATION ====\n",
      "coverage: 0.7676\n",
      "width: 202303.42\n",
      "mae_mid: 69739.5625\n",
      "pinball10: 14833.707714199221\n",
      "pinball90: 17429.381900761717\n",
      "\n",
      "==== CatBoost VALIDATION ====\n",
      "coverage: 0.78615\n",
      "width: 223680.90167355828\n",
      "mae_mid: 74192.63504545635\n",
      "pinball10: 15416.019133191074\n",
      "pinball90: 18370.47555137105\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2852\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 223000.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2852\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1100000.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "\n",
      "✅ artifacts/submission_LightGBM.csv created\n",
      "\n",
      "✅ artifacts/submission_XGBoost.csv created\n",
      "\n",
      "✅ artifacts/submission_CatBoost.csv created\n",
      "\n",
      "✅ BOTH MODELS COMPLETED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import category_encoders as ce\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "\n",
    "TARGET = \"sale_price\"\n",
    "SEED = 42\n",
    "\n",
    "ORDINAL_COLS = [\"submarket\"]\n",
    "\n",
    "TARGET_ENC_COLS = [\n",
    "    \"city\",\"zoning\",\"subdivision\",\"join_status\"\n",
    "]\n",
    "\n",
    "DROP_BASE = [\"id\",\"sale_warning\",\"latitude\",\"longitude\"]\n",
    "\n",
    "DROP_AFTER = [\n",
    "    \"join_year\",\"sale_date\",\"sqft_lot\",\"garb_sqft\",\"gara_sqft\",\n",
    "    \"bath_full\",\"bath_3qtr\",\"bath_half\",\"beds\",\"present_use\",\n",
    "    \"sale_day\",\"sqft_1\",\"imp_val\",\"year_reno\",\"fbsmt_grade\",\n",
    "    \"view_otherwater\",\"sale_nbr\",\"view_sound\",\"grade\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# FEATURE ENGINEERING\n",
    "# =========================\n",
    "\n",
    "class HouseFE(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,df):\n",
    "\n",
    "        d = df.copy()\n",
    "\n",
    "        d = d.drop(columns=DROP_BASE, errors=\"ignore\")\n",
    "\n",
    "        d[\"sale_date\"] = pd.to_datetime(d[\"sale_date\"])\n",
    "\n",
    "        d[\"sale_year\"] = d[\"sale_date\"].dt.year\n",
    "        d[\"sale_month\"] = d[\"sale_date\"].dt.month\n",
    "        d[\"sale_day\"] = d[\"sale_date\"].dt.day\n",
    "\n",
    "        d[\"age_at_sale\"] = d[\"sale_year\"] - d[\"year_built\"]\n",
    "        d[\"reno_age_at_sale\"] = d[\"sale_year\"] - d[\"year_reno\"]\n",
    "        d[\"is_renovated\"] = (d[\"year_reno\"] > d[\"year_built\"]).astype(int)\n",
    "\n",
    "        d[\"lot_sqft_ratio\"] = d[\"sqft\"]/(d[\"sqft_lot\"]+1)\n",
    "        d[\"garage_total\"] = d[\"garb_sqft\"] + d[\"gara_sqft\"]\n",
    "\n",
    "        d[\"bath_total\"] = (\n",
    "            d[\"bath_full\"] + d[\"bath_3qtr\"] + 0.5*d[\"bath_half\"]\n",
    "        )\n",
    "\n",
    "        d[\"sqft_per_bed\"] = d[\"sqft\"]/(d[\"beds\"]+1)\n",
    "        d[\"sqft_per_bath\"] = d[\"sqft\"]/(d[\"bath_total\"]+1)\n",
    "\n",
    "        d = d.drop(columns=DROP_AFTER, errors=\"ignore\")\n",
    "\n",
    "        return d\n",
    "\n",
    "# =========================\n",
    "# METRICS\n",
    "# =========================\n",
    "\n",
    "def pinball(y,q,a):\n",
    "    d=y-q\n",
    "    return np.mean(np.maximum(a*d,(a-1)*d))\n",
    "\n",
    "def interval_metrics(y,l,u):\n",
    "    cov=np.mean((y>=l)&(y<=u))\n",
    "    width=np.mean(u-l)\n",
    "    mae_mid=mean_absolute_error(y,(l+u)/2)\n",
    "    return cov,width,mae_mid\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "\n",
    "train_df = pd.read_csv(\"data/dataset.csv\")\n",
    "test_df  = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "test_ids = test_df[\"id\"]\n",
    "\n",
    "X = train_df.drop(columns=[TARGET])\n",
    "y = train_df[TARGET]\n",
    "\n",
    "# =========================\n",
    "# VALIDATION SPLIT\n",
    "# =========================\n",
    "\n",
    "Xtr,Xval,ytr,yval = train_test_split(\n",
    "    X,y,test_size=0.2,random_state=SEED\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# PREPROCESS FIT ON TRAIN SPLIT\n",
    "# =========================\n",
    "\n",
    "fe = HouseFE()\n",
    "\n",
    "Xtr = fe.fit_transform(Xtr)\n",
    "Xval = fe.transform(Xval)\n",
    "\n",
    "target_enc = ce.TargetEncoder(\n",
    "    cols=TARGET_ENC_COLS,\n",
    "    smoothing=20,\n",
    "    min_samples_leaf=50\n",
    ")\n",
    "\n",
    "Xtr = target_enc.fit_transform(Xtr,ytr)\n",
    "Xval = target_enc.transform(Xval)\n",
    "\n",
    "ord_enc = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\",\n",
    "    unknown_value=-1\n",
    ")\n",
    "\n",
    "Xtr[ORDINAL_COLS] = ord_enc.fit_transform(Xtr[ORDINAL_COLS])\n",
    "Xval[ORDINAL_COLS] = ord_enc.transform(Xval[ORDINAL_COLS])\n",
    "\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "Xtr = pd.DataFrame(imp.fit_transform(Xtr),columns=Xtr.columns)\n",
    "Xval = pd.DataFrame(imp.transform(Xval),columns=Xval.columns)\n",
    "\n",
    "# =========================\n",
    "# MODEL BUILDERS\n",
    "# =========================\n",
    "\n",
    "def build_lgbm(alpha):\n",
    "    return LGBMRegressor(\n",
    "        objective=\"quantile\",\n",
    "        alpha=alpha,\n",
    "        n_estimators=900,\n",
    "        learning_rate=0.04,\n",
    "        num_leaves=31,\n",
    "        min_child_samples=100,\n",
    "        subsample=0.8,\n",
    "        feature_fraction=0.8,\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "def build_xgb(alpha):\n",
    "    return XGBRegressor(\n",
    "        objective=\"reg:quantileerror\",\n",
    "        quantile_alpha=alpha,\n",
    "        n_estimators=900,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.04,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        tree_method=\"hist\",\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "def build_catboost(alpha):\n",
    "    return CatBoostRegressor(\n",
    "        loss_function=f\"Quantile:alpha={alpha}\",\n",
    "        iterations=900,\n",
    "        depth=6,\n",
    "        learning_rate=0.04,\n",
    "        subsample=0.8,\n",
    "        random_seed=SEED,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================\n",
    "# VALIDATION EVALUATION\n",
    "# =========================\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, builder in {\n",
    "    \"LightGBM\": build_lgbm,\n",
    "    \"XGBoost\": build_xgb,\n",
    "    \"CatBoost\": build_catboost\n",
    "}.items():\n",
    "\n",
    "\n",
    "    low = builder(0.1)\n",
    "    up  = builder(0.9)\n",
    "\n",
    "    low.fit(Xtr,ytr)\n",
    "    up.fit(Xtr,ytr)\n",
    "\n",
    "    l = low.predict(Xval)\n",
    "    u = up.predict(Xval)\n",
    "\n",
    "    l,u = np.minimum(l,u),np.maximum(l,u)\n",
    "\n",
    "    cov,width,mae_mid = interval_metrics(yval,l,u)\n",
    "\n",
    "    print(f\"\\n==== {name} VALIDATION ====\")\n",
    "    print(\"coverage:\",cov)\n",
    "    print(\"width:\",width)\n",
    "    print(\"mae_mid:\",mae_mid)\n",
    "    print(\"pinball10:\",pinball(yval,l,0.1))\n",
    "    print(\"pinball90:\",pinball(yval,u,0.9))\n",
    "    print(f\"========\")\n",
    "    print(f\"========\\n\")\n",
    "\n",
    "    results[name] = (low,up)\n",
    "\n",
    "# =========================\n",
    "# REFIT PREPROCESS ON FULL TRAIN\n",
    "# =========================\n",
    "\n",
    "X_full = fe.fit_transform(X)\n",
    "X_full = target_enc.fit_transform(X_full,y)\n",
    "X_full[ORDINAL_COLS] = ord_enc.fit_transform(X_full[ORDINAL_COLS])\n",
    "X_full = pd.DataFrame(imp.fit_transform(X_full),columns=X_full.columns)\n",
    "\n",
    "# =========================\n",
    "# TEST PREPROCESS\n",
    "# =========================\n",
    "\n",
    "X_test = fe.transform(test_df)\n",
    "X_test = target_enc.transform(X_test)\n",
    "X_test[ORDINAL_COLS] = ord_enc.transform(X_test[ORDINAL_COLS])\n",
    "X_test = pd.DataFrame(imp.transform(X_test),columns=X_test.columns)\n",
    "\n",
    "# =========================\n",
    "# FINAL TRAIN + TEST PREDICT\n",
    "# =========================\n",
    "\n",
    "for name, builder in {\n",
    "    \"LightGBM\": build_lgbm,\n",
    "    \"XGBoost\": build_xgb,\n",
    "    \"CatBoost\": build_catboost\n",
    "}.items():\n",
    "\n",
    "\n",
    "    low = builder(0.1)\n",
    "    up  = builder(0.9)\n",
    "\n",
    "    low.fit(X_full,y)\n",
    "    up.fit(X_full,y)\n",
    "\n",
    "    l = low.predict(X_test)\n",
    "    u = up.predict(X_test)\n",
    "\n",
    "    l,u = np.minimum(l,u),np.maximum(l,u)\n",
    "\n",
    "    sub = pd.DataFrame({\n",
    "        \"id\": test_ids,\n",
    "        \"pi_lower\": l,\n",
    "        \"pi_upper\": u\n",
    "    })\n",
    "\n",
    "    fname = f\"artifacts/submission_{name}.csv\"\n",
    "    sub.to_csv(fname,index=False)\n",
    "\n",
    "    print(f\"\\n✅ {fname} created\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7075d33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saadenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
